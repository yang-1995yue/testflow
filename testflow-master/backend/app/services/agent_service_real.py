"""
æ™ºèƒ½ä½“ç®¡ç†æœåŠ¡
æ”¯æŒé‡è¯•æœºåˆ¶ã€è¶…æ—¶æ§åˆ¶å’Œå¹¶å‘é…ç½®
"""
import json
import re
import asyncio
import os
from datetime import datetime
from typing import Dict, Any, Optional, List
from sqlalchemy.orm import Session

from app.models.ai_config import Agent, AIModel
from app.services.ai_service import ai_service
from app.services.settings_service import SettingsService
from app.prompts import (
    render_prompt,
    REQUIREMENT_ANALYSIS_USER,
    TEST_POINT_USER,
    TEST_CASE_DESIGN_USER,
    TEST_CASE_BATCH_OPTIMIZE_USER
)


class AgentServiceReal:
    """æ™ºèƒ½ä½“æœåŠ¡ç±»
    
    æ”¯æŒä»ç³»ç»Ÿè®¾ç½®åŠ è½½é…ç½®ï¼š
    - retry_count: å¤±è´¥é‡è¯•æ¬¡æ•°
    - task_timeout: å•æ¬¡AIè°ƒç”¨è¶…æ—¶æ—¶é—´
    - max_concurrent_tasks: æœ€å¤§å¹¶å‘æ•°
    """
    
    # é»˜è®¤é…ç½®
    DEFAULT_RETRY_COUNT = 3
    DEFAULT_TASK_TIMEOUT = 300  # ç§’ï¼ˆä¸ httpx å’Œç³»ç»Ÿè®¾ç½®ä¿æŒä¸€è‡´ï¼‰
    DEFAULT_RETRY_DELAY = 1  # é‡è¯•å»¶è¿ŸåŸºæ•°ï¼ˆç§’ï¼‰
    
    @staticmethod
    def _normalize_priority(priority: str) -> str:
        """æ ‡å‡†åŒ–ä¼˜å…ˆçº§å€¼
        
        å°† P0/P1/P2/HIGH/MEDIUM/LOW ç­‰æ ¼å¼ç»Ÿä¸€è½¬æ¢ä¸º high/medium/low
        """
        if not priority:
            return "medium"
        
        priority_map = {
            "P0": "high",
            "HIGH": "high",
            "H": "high",
            "P1": "medium",
            "MEDIUM": "medium",
            "M": "medium",
            "P2": "low",
            "LOW": "low",
            "L": "low"
        }
        return priority_map.get(priority.upper(), "medium")
    
    def __init__(self, db: Optional[Session] = None):
        self.db = db
        # é…ç½®å‚æ•°ï¼ˆä»ç³»ç»Ÿè®¾ç½®åŠ è½½ï¼‰
        self._retry_count = self.DEFAULT_RETRY_COUNT
        self._task_timeout = self.DEFAULT_TASK_TIMEOUT
        self._retry_delay = self.DEFAULT_RETRY_DELAY
        self._config_loaded = False
    
    def _load_config(self) -> None:
        """ä»ç³»ç»Ÿè®¾ç½®åŠ è½½é…ç½®"""
        if self._config_loaded:
            return
        
        try:
            if self.db:
                config = SettingsService.get_concurrency_config(self.db)
                self._retry_count = config.retry_count
                self._task_timeout = config.task_timeout
                self._config_loaded = True
                print(f"ğŸ”§ [AgentService] å·²åŠ è½½é…ç½®: retry_count={self._retry_count}, task_timeout={self._task_timeout}s")
        except Exception as e:
            print(f"âš ï¸ [AgentService] åŠ è½½é…ç½®å¤±è´¥ï¼Œä½¿ç”¨é»˜è®¤å€¼: {e}")
    
    def reload_config(self) -> None:
        """å¼ºåˆ¶é‡æ–°åŠ è½½é…ç½®"""
        self._config_loaded = False
        self._load_config()
    
    def _get_test_categories_text(self) -> str:
        """è·å–æµ‹è¯•ç±»åˆ«æ–‡æœ¬"""
        if not self.db:
            return "- functional: åŠŸèƒ½æµ‹è¯•\n- performance: æ€§èƒ½æµ‹è¯•\n- security: å®‰å…¨æµ‹è¯•"
        categories = SettingsService.get_test_categories(self.db, active_only=True)
        if not categories:
            return "- functional: åŠŸèƒ½æµ‹è¯•\n- performance: æ€§èƒ½æµ‹è¯•\n- security: å®‰å…¨æµ‹è¯•"
        return "\n".join([f"- {c.code}: {c.name}" for c in categories])
    
    def _get_design_methods_text(self) -> str:
        """è·å–æµ‹è¯•è®¾è®¡æ–¹æ³•æ–‡æœ¬ï¼ˆåŒ…å«codeå’Œnameï¼Œä¾¿äºAIè¿”å›æ­£ç¡®çš„codeï¼‰"""
        if not self.db:
            return "- equivalence_partitioning: ç­‰ä»·ç±»åˆ’åˆ†æ³•\n- boundary_value: è¾¹ç•Œå€¼åˆ†ææ³•\n- scenario: åœºæ™¯æ³•"
        methods = SettingsService.get_design_methods(self.db, active_only=True)
        if not methods:
            return "- equivalence_partitioning: ç­‰ä»·ç±»åˆ’åˆ†æ³•\n- boundary_value: è¾¹ç•Œå€¼åˆ†ææ³•\n- scenario: åœºæ™¯æ³•"
        return "\n".join([f"- {m.code}: {m.name}" for m in methods])
    
    async def _get_agent_config(self, agent_id: int) -> Dict[str, Any]:
        """è·å–æ™ºèƒ½ä½“é…ç½®"""
        if not self.db:
            raise Exception("æ•°æ®åº“è¿æ¥æœªåˆå§‹åŒ–")
        agent = self.db.query(Agent).filter(Agent.id == agent_id).first()
        if not agent:
            raise Exception(f"æ™ºèƒ½ä½“ä¸å­˜åœ¨: {agent_id}")
        if not agent.is_active:
            raise Exception(f"æ™ºèƒ½ä½“æœªæ¿€æ´»: {agent.name}")
        if not agent.system_prompt:
            raise Exception(f"æ™ºèƒ½ä½“ {agent.name} æœªé…ç½®ç³»ç»Ÿæç¤ºè¯")
        
        ai_model = self.db.query(AIModel).filter(AIModel.id == agent.ai_model_id).first()
        if not ai_model:
            raise Exception("æ™ºèƒ½ä½“å…³è”çš„AIæ¨¡å‹ä¸å­˜åœ¨")
        if not ai_model.api_key:
            raise Exception(f"AIæ¨¡å‹ {ai_model.name} æœªé…ç½®APIå¯†é’¥")
        
        return {
            "model": ai_model.model_id,
            "api_key": ai_model.api_key,
            "base_url": ai_model.base_url,
            "temperature": agent.temperature,
            "max_tokens": agent.max_tokens,
            "system_prompt": agent.system_prompt
        }
    
    async def _call_ai_once(self, config: Dict[str, Any], user_prompt: str, image_paths: Optional[List[str]] = None) -> str:
        """å•æ¬¡è°ƒç”¨AIï¼ˆä¸å¸¦é‡è¯•ï¼‰"""
        if image_paths:
            # å¯ä»¥æ¥å—å›¾åƒè¯·æ±‚ï¼Œç›´æ¥è°ƒç”¨å¤šæ¨¡æ€API
            return await ai_service.call_ai_multimodal(
                model=config["model"], text_content=user_prompt, image_paths=image_paths,
                api_key=config["api_key"], base_url=config["base_url"],
                system_prompt=config["system_prompt"], temperature=config["temperature"], max_tokens=config["max_tokens"]
            )
        messages = [{"role": "system", "content": config["system_prompt"]}, {"role": "user", "content": user_prompt}]
        return await ai_service.call_ai(
            model=config["model"], messages=messages, api_key=config["api_key"],
            base_url=config["base_url"], temperature=config["temperature"], max_tokens=config["max_tokens"]
        )
    
    async def _call_ai(self, config: Dict[str, Any], user_prompt: str, image_paths: Optional[List[str]] = None) -> str:
        """è°ƒç”¨AIï¼ˆå¸¦é‡è¯•å’Œè¶…æ—¶æœºåˆ¶ï¼‰
        
        ä½¿ç”¨ç³»ç»Ÿè®¾ç½®ä¸­çš„ retry_count å’Œ task_timeout å‚æ•°
        é‡‡ç”¨æŒ‡æ•°é€€é¿ç­–ç•¥è¿›è¡Œé‡è¯•
        """
        # ç¡®ä¿é…ç½®å·²åŠ è½½
        self._load_config()
        
        last_error = None
        max_attempts = self._retry_count + 1  # é‡è¯•æ¬¡æ•° + é¦–æ¬¡å°è¯•
        
        for attempt in range(max_attempts):
            try:
                # ä½¿ç”¨è¶…æ—¶æ§åˆ¶
                result = await asyncio.wait_for(
                    self._call_ai_once(config, user_prompt, image_paths),
                    timeout=self._task_timeout
                )
                
                if attempt > 0:
                    print(f"âœ… AIè°ƒç”¨æˆåŠŸ (ç¬¬ {attempt + 1} æ¬¡å°è¯•)")
                
                return result
                
            except asyncio.TimeoutError:
                last_error = f"AIè°ƒç”¨è¶…æ—¶ï¼ˆè¶…è¿‡{self._task_timeout}ç§’ï¼‰"
                print(f"â±ï¸ AIè°ƒç”¨è¶…æ—¶ (å°è¯• {attempt + 1}/{max_attempts}): {last_error}")
                
            except Exception as e:
                last_error = str(e)
                print(f"âŒ AIè°ƒç”¨å¤±è´¥ (å°è¯• {attempt + 1}/{max_attempts}): {last_error}")
            
            # å¦‚æœè¿˜æœ‰é‡è¯•æœºä¼šï¼Œç­‰å¾…åé‡è¯•
            if attempt < max_attempts - 1:
                # æŒ‡æ•°é€€é¿ï¼š1s, 2s, 4s, 8s...
                delay = self._retry_delay * (2 ** attempt)
                print(f"â³ ç­‰å¾… {delay} ç§’åé‡è¯•...")
                await asyncio.sleep(delay)
        
        # æ‰€æœ‰é‡è¯•éƒ½å¤±è´¥
        raise Exception(f"AIè°ƒç”¨å¤±è´¥ï¼ˆå·²é‡è¯•{self._retry_count}æ¬¡ï¼‰: {last_error}")
    
    async def _call_ai_with_parse(self, config: Dict[str, Any], user_prompt: str, image_paths: Optional[List[str]] = None) -> Dict[str, Any]:
        """è°ƒç”¨AIå¹¶è§£æJSONï¼ˆå¸¦é‡è¯•æœºåˆ¶ï¼‰
        
        æ•´åˆäº† AI è°ƒç”¨å’Œ JSON è§£æï¼Œä»»ä½•ç¯èŠ‚å¤±è´¥éƒ½ä¼šè§¦å‘é‡è¯•
        è¿™æ ·å¯ä»¥å¤„ç†ï¼š
        - ç½‘ç»œé”™è¯¯
        - API è¶…æ—¶
        - JSON æ ¼å¼é”™è¯¯
        - å“åº”æˆªæ–­
        """
        # ç¡®ä¿é…ç½®å·²åŠ è½½
        self._load_config()
        
        last_error = None
        max_attempts = self._retry_count + 1
        
        for attempt in range(max_attempts):
            try:
                # è°ƒç”¨ AI
                response = await asyncio.wait_for(
                    self._call_ai_once(config, user_prompt, image_paths),
                    timeout=self._task_timeout
                )
                
                # è§£æ JSON
                result = self._parse_json(response)
                
                if attempt > 0:
                    print(f"âœ… AIè°ƒç”¨å¹¶è§£ææˆåŠŸ (ç¬¬ {attempt + 1} æ¬¡å°è¯•)")
                
                return result
                
            except asyncio.TimeoutError:
                last_error = f"AIè°ƒç”¨è¶…æ—¶ï¼ˆè¶…è¿‡{self._task_timeout}ç§’ï¼‰"
                print(f"â±ï¸ AIè°ƒç”¨è¶…æ—¶ (å°è¯• {attempt + 1}/{max_attempts}): {last_error}")
                
            except Exception as e:
                last_error = str(e)
                error_type = "JSONè§£æå¤±è´¥" if "æ— æ³•è§£æJSON" in str(e) else "AIè°ƒç”¨å¤±è´¥"
                print(f"âŒ {error_type} (å°è¯• {attempt + 1}/{max_attempts}): {last_error}")
            
            # å¦‚æœè¿˜æœ‰é‡è¯•æœºä¼šï¼Œç­‰å¾…åé‡è¯•
            if attempt < max_attempts - 1:
                delay = self._retry_delay * (2 ** attempt)
                print(f"â³ ç­‰å¾… {delay} ç§’åé‡è¯•...")
                await asyncio.sleep(delay)
        
        # æ‰€æœ‰é‡è¯•éƒ½å¤±è´¥
        raise Exception(f"AIè°ƒç”¨å¤±è´¥ï¼ˆå·²é‡è¯•{self._retry_count}æ¬¡ï¼‰: {last_error}")
    
    async def _call_ai_with_parse(self, config: Dict[str, Any], user_prompt: str, image_paths: Optional[List[str]] = None) -> Dict[str, Any]:
        """è°ƒç”¨AIå¹¶è§£æJSONï¼ˆå¸¦é‡è¯•æœºåˆ¶ï¼‰
        
        å¦‚æœJSONè§£æå¤±è´¥ï¼Œä¼šé‡æ–°è°ƒç”¨AIï¼ˆå› ä¸ºå¯èƒ½æ˜¯AIè¿”å›æ ¼å¼é”™è¯¯ï¼‰
        """
        # ç¡®ä¿é…ç½®å·²åŠ è½½
        self._load_config()
        
        last_error = None
        max_attempts = self._retry_count + 1
        
        for attempt in range(max_attempts):
            try:
                # è°ƒç”¨AIï¼ˆå·²åŒ…å«ç½‘ç»œé‡è¯•ï¼‰
                response = await self._call_ai(config, user_prompt, image_paths)
                
                # å°è¯•è§£æJSON
                result = self._parse_json(response)
                
                if attempt > 0:
                    print(f"âœ… JSONè§£ææˆåŠŸ (ç¬¬ {attempt + 1} æ¬¡å°è¯•)")
                
                return result
                
            except Exception as e:
                error_msg = str(e)
                
                # åˆ¤æ–­æ˜¯å¦æ˜¯JSONè§£æé”™è¯¯
                if "æ— æ³•è§£æJSON" in error_msg:
                    last_error = f"JSONè§£æå¤±è´¥: {error_msg}"
                    print(f"ğŸ“ JSONè§£æå¤±è´¥ (å°è¯• {attempt + 1}/{max_attempts}): AIè¿”å›æ ¼å¼é”™è¯¯")
                else:
                    # å…¶ä»–é”™è¯¯ï¼ˆç½‘ç»œã€è¶…æ—¶ç­‰ï¼‰å·²ç»åœ¨ _call_ai ä¸­é‡è¯•è¿‡äº†
                    raise
                
                # å¦‚æœè¿˜æœ‰é‡è¯•æœºä¼šï¼Œç­‰å¾…åé‡è¯•
                if attempt < max_attempts - 1:
                    delay = self._retry_delay * (2 ** attempt)
                    print(f"â³ ç­‰å¾… {delay} ç§’åé‡æ–°è¯·æ±‚AI...")
                    await asyncio.sleep(delay)
        
        # æ‰€æœ‰é‡è¯•éƒ½å¤±è´¥
        raise Exception(f"AIå“åº”è§£æå¤±è´¥ï¼ˆå·²é‡è¯•{self._retry_count}æ¬¡ï¼‰: {last_error}")
    
    def _parse_json(self, response: str) -> Dict[str, Any]:
        """è§£æJSONï¼Œæ”¯æŒæå–```json```ä»£ç å—"""
        # 1. ç›´æ¥è§£æ
        try:
            return json.loads(response)
        except Exception as e1:
            print(f"âš ï¸ ç›´æ¥JSONè§£æå¤±è´¥: {str(e1)[:100]}")
        
        # 2. æå– ```json ... ``` ä»£ç å—
        match = re.search(r'```json\s*([\s\S]*?)\s*```', response)
        if match:
            try:
                return json.loads(match.group(1))
            except Exception as e2:
                print(f"âš ï¸ ä»£ç å—JSONè§£æå¤±è´¥: {str(e2)[:100]}")
        
        # 3. æå–ç¬¬ä¸€ä¸ª {...} å—
        match = re.search(r'\{[\s\S]*\}', response)
        if match:
            try:
                return json.loads(match.group(0))
            except Exception as e3:
                print(f"âš ï¸ èŠ±æ‹¬å·å—JSONè§£æå¤±è´¥: {str(e3)[:100]}")
        
        # ä¿å­˜å®Œæ•´å“åº”åˆ°æ—¥å¿—æ–‡ä»¶
        from pathlib import Path
        from datetime import datetime
        
        log_dir = Path("logs")
        log_dir.mkdir(parents=True, exist_ok=True)
        timestamp = datetime.now().strftime("%Y%m%d_%H%M%S_%f")
        log_file = log_dir / f"failed_response_{timestamp}.txt"
        
        try:
            log_file.write_text(
                f"{'='*80}\n"
                f"AIå“åº”JSONè§£æå¤±è´¥\n"
                f"{'='*80}\n\n"
                f"å“åº”é•¿åº¦: {len(response)} å­—ç¬¦\n\n"
                f"å®Œæ•´å“åº”å†…å®¹:\n"
                f"{'-'*80}\n"
                f"{response}\n"
                f"{'-'*80}\n",
                encoding='utf-8'
            )
            print(f"ğŸ“ å®Œæ•´å“åº”å·²ä¿å­˜åˆ°: {log_file}")
        except Exception as save_err:
            print(f"âš ï¸ ä¿å­˜æ—¥å¿—æ–‡ä»¶å¤±è´¥: {save_err}")
        
        # æ‰“å°åŸå§‹å“åº”ç”¨äºè°ƒè¯•
        print(f"\n{'='*80}")
        print(f"âŒ JSONè§£æå®Œå…¨å¤±è´¥")
        print(f"{'='*80}")
        print(f"å“åº”é•¿åº¦: {len(response)} å­—ç¬¦")
        print(f"åŸå§‹å“åº” (å‰1000å­—ç¬¦):")
        print(response[:1000])
        if len(response) > 1000:
            print(f"\n... (çœç•¥ {len(response) - 1000} å­—ç¬¦) ...\n")
            print(f"åŸå§‹å“åº” (æœ€å500å­—ç¬¦):")
            print(response[-500:])
        print(f"{'='*80}\n")
        
        raise Exception(f"æ— æ³•è§£æJSON: {response[:200]}...")

    # ==================== æ ¸å¿ƒæ–¹æ³• ====================
    
    async def analyze_requirements(self, agent_id: int, content: str, image_paths: Optional[List[str]] = None) -> Dict[str, Any]:
        """åˆ†æéœ€æ±‚"""
        config = await self._get_agent_config(agent_id)
        user_prompt = render_prompt(REQUIREMENT_ANALYSIS_USER, content=content)
        result = await self._call_ai_with_parse(config, user_prompt, image_paths)
        
        # æ£€æŸ¥AIè¿”å›çš„éœ€æ±‚ç‚¹æ˜¯å¦ä¸ºç©º
        requirement_points = result.get("requirement_points", [])
        if not requirement_points:
            print("âš ï¸ AIè¿”å›äº†ç©ºçš„éœ€æ±‚ç‚¹æ•°ç»„ï¼Œæ­£åœ¨å°è¯•ä¼˜åŒ–æç¤ºè¯å¹¶é‡æ–°è°ƒç”¨...")
            
            # ä¼˜åŒ–æç¤ºè¯ï¼šæ·»åŠ æ›´æ˜ç¡®çš„è¦æ±‚
            optimized_prompt = render_prompt(REQUIREMENT_ANALYSIS_USER, content=content)
            optimized_prompt += "\n\né‡è¦æé†’ï¼šè¯·ç¡®ä¿è‡³å°‘ç”Ÿæˆ1ä¸ªéœ€æ±‚ç‚¹ï¼Œå³ä½¿éœ€æ±‚æ–‡æ¡£å†…å®¹è¾ƒå°‘ã€‚"
            
            # é‡æ–°è°ƒç”¨AI
            result = await self._call_ai_with_parse(config, optimized_prompt, image_paths)
            requirement_points = result.get("requirement_points", [])
            
            if not requirement_points:
                print("âŒ é‡æ–°è°ƒç”¨AIä»ç„¶è¿”å›ç©ºçš„éœ€æ±‚ç‚¹æ•°ç»„")
                # å¦‚æœè¿˜æ˜¯è¿”å›ç©ºï¼Œè‡³å°‘è¿”å›ä¸€ä¸ªé»˜è®¤çš„éœ€æ±‚ç‚¹ï¼Œé¿å…å‰ç«¯æŠ¥é”™
                result["requirement_points"] = [{"content": "æœªæå–åˆ°å…·ä½“éœ€æ±‚ç‚¹", "module": "é»˜è®¤æ¨¡å—", "priority": "medium", "order_index": 1}]
            else:
                print(f"âœ… é‡æ–°è°ƒç”¨AIæˆåŠŸï¼Œç”Ÿæˆäº† {len(requirement_points)} ä¸ªéœ€æ±‚ç‚¹")
        
        print(f"ğŸ“Š æœ€ç»ˆç”Ÿæˆçš„éœ€æ±‚ç‚¹æ•°é‡: {len(result.get('requirement_points', []))}")
        return result
    
    async def generate_test_points(self, agent_id: int, requirement_content: str) -> Dict[str, Any]:
        """ç”Ÿæˆæµ‹è¯•ç‚¹"""
        config = await self._get_agent_config(agent_id)
        user_prompt = render_prompt(
            TEST_POINT_USER, 
            content=requirement_content, 
            test_categories=self._get_test_categories_text(),
            design_methods=self._get_design_methods_text()
        )
        return await self._call_ai_with_parse(config, user_prompt)
    
    async def design_test_case(
        self, 
        agent_id: int, 
        test_point: dict,  # å®Œæ•´çš„æµ‹è¯•ç‚¹JSONå¯¹è±¡
        requirement_content: str = ""  # åŸå§‹éœ€æ±‚æ–‡æ¡£å†…å®¹
    ) -> Dict[str, Any]:
        """è®¾è®¡æµ‹è¯•ç”¨ä¾‹ï¼ˆå…¼å®¹å•ä¸ªå’Œæ‰¹é‡ï¼‰
        
        Args:
            agent_id: æ™ºèƒ½ä½“ID
            test_point: å®Œæ•´çš„æµ‹è¯•ç‚¹å¯¹è±¡ï¼ŒåŒ…å« id, content, test_type, design_method, priority ç­‰
            requirement_content: åŸå§‹éœ€æ±‚æ–‡æ¡£å†…å®¹ï¼Œæä¾›ä¸šåŠ¡ä¸Šä¸‹æ–‡
            
        Returns:
            å•ä¸ªæµ‹è¯•ç”¨ä¾‹å¯¹è±¡
            
        Note:
            å†…éƒ¨è°ƒç”¨ç»Ÿä¸€çš„æ‰¹é‡æ¥å£ï¼Œä¼ å…¥é•¿åº¦ä¸º1çš„æ•°ç»„
        """
        # è°ƒç”¨æ‰¹é‡æ¥å£ï¼Œä¼ å…¥å•ä¸ªæµ‹è¯•ç‚¹
        cases = await self.design_test_cases_batch(
            agent_id=agent_id,
            test_points=[test_point],
            requirement_content=requirement_content
        )
        
        # è¿”å›ç¬¬ä¸€ä¸ªæµ‹è¯•ç”¨ä¾‹
        return cases[0] if cases else {}
    
    async def design_test_cases_batch(
        self, 
        agent_id: int, 
        test_points: List[dict],  # æµ‹è¯•ç‚¹æ•°ç»„ï¼ˆ1ä¸ªæˆ–å¤šä¸ªï¼‰
        requirement_content: str = ""
    ) -> List[Dict[str, Any]]:
        """æ‰¹é‡è®¾è®¡æµ‹è¯•ç”¨ä¾‹ï¼ˆç»Ÿä¸€æ¥å£ï¼‰
        
        Args:
            agent_id: æ™ºèƒ½ä½“ID
            test_points: æµ‹è¯•ç‚¹æ•°ç»„ï¼ˆå¯ä»¥æ˜¯1ä¸ªæˆ–å¤šä¸ªï¼‰
            requirement_content: åŸå§‹éœ€æ±‚æ–‡æ¡£å†…å®¹
            
        Returns:
            æµ‹è¯•ç”¨ä¾‹æ•°ç»„ï¼ˆä¸è¾“å…¥ä¸€ä¸€å¯¹åº”ï¼‰
        """
        config = await self._get_agent_config(agent_id)
        
        # å°†æµ‹è¯•ç‚¹æ•°ç»„è½¬æ¢ä¸ºJSONå­—ç¬¦ä¸²
        test_points_json = json.dumps(test_points, ensure_ascii=False, indent=2)
        
        user_prompt = render_prompt(
            TEST_CASE_DESIGN_USER,
            test_points=test_points_json,
            requirement_content=requirement_content or "ï¼ˆæ— éœ€æ±‚æ–‡æ¡£ï¼‰"
        )
        
        count = len(test_points)
        print(f"\nğŸ¯ æµ‹è¯•ç”¨ä¾‹è®¾è®¡: {count} ä¸ªæµ‹è¯•ç‚¹")
        if count <= 3:
            for tp in test_points:
                preview = tp.get('content', '')[:40]
                print(f"   - {preview}... (æ–¹æ³•: {tp.get('design_method', 'N/A')})")
        
        result = await self._call_ai_with_parse(config, user_prompt)
        
        # æ‰“å°å®Œæ•´åŸå§‹è¾“å‡º
        print(f"\n{'='*80}")
        print(f"ğŸ“‹ æ‰¹é‡ç”ŸæˆåŸå§‹è¾“å‡º (æµ‹è¯•ç‚¹æ•°é‡: {count})")
        print(f"{'='*80}")
        print(json.dumps(result, ensure_ascii=False, indent=2))
        print(f"{'='*80}\n")
        
        # æå–æµ‹è¯•ç”¨ä¾‹æ•°ç»„
        test_cases = result.get('test_cases', [])
        
        # éªŒè¯æ•°é‡åŒ¹é…
        if len(test_cases) != len(test_points):
            print(f"âš ï¸ è­¦å‘Šï¼šæµ‹è¯•ç”¨ä¾‹æ•°é‡ä¸åŒ¹é…ï¼ˆæœŸæœ›{len(test_points)}ï¼Œå®é™…{len(test_cases)}ï¼‰")
            # å¦‚æœæ•°é‡ä¸åŒ¹é…ï¼Œå°è¯•è¡¥é½æˆ–æˆªæ–­
            if len(test_cases) < len(test_points):
                print(f"âš ï¸ æµ‹è¯•ç”¨ä¾‹æ•°é‡ä¸è¶³ï¼Œå°†ä½¿ç”¨ç©ºå¯¹è±¡è¡¥é½")
                while len(test_cases) < len(test_points):
                    test_cases.append({})
            elif len(test_cases) > len(test_points):
                print(f"âš ï¸ æµ‹è¯•ç”¨ä¾‹æ•°é‡è¿‡å¤šï¼Œå°†æˆªæ–­")
                test_cases = test_cases[:len(test_points)]
        
        print(f"âœ… ç”Ÿæˆ {len(test_cases)} ä¸ªæµ‹è¯•ç”¨ä¾‹")
        
        return test_cases
    
    async def optimize_test_cases(self, agent_id: int, test_cases: List[Dict[str, Any]]) -> Dict[str, Any]:
        """æ‰¹é‡ä¼˜åŒ–æµ‹è¯•ç”¨ä¾‹"""
        config = await self._get_agent_config(agent_id)
        user_prompt = render_prompt(TEST_CASE_BATCH_OPTIMIZE_USER, test_cases=json.dumps(test_cases, ensure_ascii=False, indent=2))
        return await self._call_ai_with_parse(config, user_prompt)

    # ==================== æ‰§è¡Œæ–¹æ³• ====================
    
    # ==================== æ‰§è¡Œæ–¹æ³•ï¼ˆç”¨äºå¼‚æ­¥ä»»åŠ¡ï¼‰ ====================
    
    async def execute_requirement_analysis(
        self,
        requirement_content: str,
        project_context: str = "",
        user_id: int = 1,
        agent_id: Optional[int] = None,
        image_paths: Optional[List[str]] = None
    ) -> Dict[str, Any]:
        """æ‰§è¡Œéœ€æ±‚åˆ†æï¼ˆåŒæ­¥æ¨¡å¼ï¼‰
        
        Args:
            requirement_content: éœ€æ±‚æ–‡æ¡£å†…å®¹
            project_context: é¡¹ç›®ä¸Šä¸‹æ–‡
            user_id: ç”¨æˆ·ID
            agent_id: æ™ºèƒ½ä½“ID
            image_paths: å›¾ç‰‡è·¯å¾„åˆ—è¡¨
            
        Returns:
            åŒ…å« success, data, error çš„å­—å…¸
        """
        try:
            # åŠ è½½é…ç½®
            if self.db:
                from app.services.async_task_manager import task_manager
                task_manager.load_config_from_db(self.db)
                self._load_config()
            
            # è°ƒç”¨åˆ†ææ–¹æ³•
            result = await self.analyze_requirements(
                agent_id=agent_id,
                content=requirement_content,
                image_paths=image_paths
            )
            
            return {
                "success": True,
                "data": result
            }
            
        except Exception as e:
            print(f"âŒ éœ€æ±‚åˆ†æå¤±è´¥: {e}")
            return {
                "success": False,
                "error": str(e)
            }
    
    async def execute_test_point_generation(
        self, 
        requirement_points: List[dict], 
        user_id: int = 1, 
        agent_id: Optional[int] = None, 
        task_id: Optional[str] = None,
        progress_offset: float = 0,
        progress_scale: float = 1.0
    ) -> Dict[str, Any]:
        """å¹¶å‘ç”Ÿæˆæµ‹è¯•ç‚¹
        
        æ¯ä¸ªéœ€æ±‚ç‚¹å•ç‹¬è°ƒç”¨AIç”Ÿæˆæµ‹è¯•ç‚¹ï¼Œä½¿ç”¨ç³»ç»Ÿè®¾ç½®çš„å¹¶å‘æ•°æ§åˆ¶åŒæ—¶æ‰§è¡Œçš„ä»»åŠ¡æ•°
        
        Args:
            requirement_points: éœ€æ±‚ç‚¹åˆ—è¡¨
            user_id: ç”¨æˆ·ID
            agent_id: æ™ºèƒ½ä½“ID
            task_id: ä»»åŠ¡IDï¼ˆç”¨äºè¿›åº¦æ›´æ–°ï¼‰
            progress_offset: è¿›åº¦åç§»ï¼ˆ0-100ï¼‰
            progress_scale: è¿›åº¦ç¼©æ”¾æ¯”ä¾‹ï¼ˆ0-1ï¼‰
        """
        from app.services.async_task_manager import task_manager
        if self.db:
            task_manager.load_config_from_db(self.db)
            self._load_config()  # åŒæ­¥åŠ è½½é…ç½®
        
        concurrency = task_manager.max_concurrent_tasks
        
        print(f"\nğŸš€ å¹¶å‘æµ‹è¯•ç‚¹ç”Ÿæˆ: {len(requirement_points)} ä¸ªéœ€æ±‚ç‚¹")
        print(f"ğŸ”§ é…ç½®: å¹¶å‘={concurrency}, é‡è¯•={self._retry_count}æ¬¡, è¶…æ—¶={self._task_timeout}s")
        
        # æ¸…ç©ºè¿™äº›éœ€æ±‚ç‚¹ç›¸å…³çš„æ—§æµ‹è¯•ç‚¹ï¼ˆçº§è”åˆ é™¤æµ‹è¯•ç”¨ä¾‹ï¼‰
        if self.db and requirement_points:
            from app.models.testcase import TestPoint
            req_point_ids = [rp.get("id") for rp in requirement_points if rp.get("id")]
            if req_point_ids:
                old_test_points = self.db.query(TestPoint).filter(
                    TestPoint.requirement_point_id.in_(req_point_ids)
                ).all()
                
                if old_test_points:
                    print(f"ğŸ—‘ï¸  æ¸…ç©º {len(old_test_points)} ä¸ªæ—§æµ‹è¯•ç‚¹ï¼ˆåŠå…¶å…³è”çš„æµ‹è¯•ç”¨ä¾‹ï¼‰")
                    for tp in old_test_points:
                        self.db.delete(tp)
                    self.db.flush()
        
        try:
            all_points = []
            completed = 0
            lock = asyncio.Lock()
            semaphore = asyncio.Semaphore(concurrency)  # æ§åˆ¶å¹¶å‘æ•°
            
            async def process_requirement(req_point, idx):
                """å¤„ç†å•ä¸ªéœ€æ±‚ç‚¹"""
                nonlocal completed
                
                async with semaphore:  # æ§åˆ¶å¹¶å‘
                    try:
                        # å•ä¸ªéœ€æ±‚ç‚¹ç”Ÿæˆæµ‹è¯•ç‚¹
                        result = await self.generate_test_points(agent_id, req_point.get('content', str(req_point)))
                        
                        test_points = result.get("test_points", [])
                        # å…³è”éœ€æ±‚ç‚¹ID
                        for tp in test_points:
                            tp["requirement_point_id"] = req_point.get("id")
                        
                        print(f"âœ… [{idx+1}/{len(requirement_points)}] éœ€æ±‚ç‚¹ç”Ÿæˆ {len(test_points)} ä¸ªæµ‹è¯•ç‚¹")
                        
                        # æ›´æ–°è¿›åº¦ï¼ˆçº¿ç¨‹å®‰å…¨ï¼‰
                        async with lock:
                            completed += 1
                            all_points.extend(test_points)
                            if task_id:
                                raw_progress = (completed / len(requirement_points)) * 100
                                scaled_progress = progress_offset + raw_progress * progress_scale
                                task_manager.update_progress(task_id, int(scaled_progress))
                        
                        return test_points
                        
                    except Exception as e:
                        print(f"âŒ [{idx+1}/{len(requirement_points)}] éœ€æ±‚ç‚¹ç”Ÿæˆå¤±è´¥: {e}")
                        # æ›´æ–°è¿›åº¦ï¼ˆå³ä½¿å¤±è´¥ä¹Ÿè¦æ›´æ–°ï¼‰
                        async with lock:
                            completed += 1
                            if task_id:
                                raw_progress = (completed / len(requirement_points)) * 100
                                scaled_progress = progress_offset + raw_progress * progress_scale
                                task_manager.update_progress(task_id, int(scaled_progress))
                        return []
            
            # å¹¶å‘å¤„ç†æ‰€æœ‰éœ€æ±‚ç‚¹
            await asyncio.gather(*[process_requirement(rp, i) for i, rp in enumerate(requirement_points)])
            
            print(f"ğŸ‰ æµ‹è¯•ç‚¹ç”Ÿæˆå®Œæˆ, å…±ç”Ÿæˆ {len(all_points)} ä¸ªæµ‹è¯•ç‚¹")
            
            return {"success": True, "data": {"test_points": all_points}}
            
        except Exception as e:
            print(f"âŒ æµ‹è¯•ç‚¹ç”Ÿæˆå¤±è´¥: {e}")
            return {"success": False, "error": str(e)}
    

    
    async def execute_test_case_design_batch(
        self, 
        test_points: List[dict],
        module_id: int,  # æ–°å¢ï¼šæ¨¡å—IDï¼Œç”¨äºæŸ¥è¯¢éœ€æ±‚æ–‡æ¡£
        user_id: int = 1, 
        agent_id: Optional[int] = None, 
        task_id: Optional[str] = None,
        on_batch_complete: Optional[callable] = None,  # æ‰¹æ¬¡å®Œæˆå›è°ƒï¼Œç”¨äºå®æ—¶ä¿å­˜
        progress_offset: float = 0,  # è¿›åº¦åç§»ï¼ˆ0-100ï¼‰
        progress_scale: float = 1.0  # è¿›åº¦ç¼©æ”¾æ¯”ä¾‹ï¼ˆ0-1ï¼‰
    ) -> Dict[str, Any]:
        """æ‰¹é‡ç”Ÿæˆæµ‹è¯•ç”¨ä¾‹ï¼ˆæ‰¹æ¬¡ç”Ÿæˆï¼šæ¯6ä¸ªæµ‹è¯•ç‚¹ä¸ºä¸€æ‰¹ï¼‰
        
        Args:
            test_points: æµ‹è¯•ç‚¹åˆ—è¡¨ï¼ˆå®Œæ•´çš„JSONå¯¹è±¡ï¼ŒåŒ…å«id, content, test_type, design_method, priorityç­‰ï¼‰
            module_id: æ¨¡å—IDï¼Œç”¨äºæŸ¥è¯¢åŸå§‹éœ€æ±‚æ–‡æ¡£
            user_id: ç”¨æˆ·ID
            agent_id: æ™ºèƒ½ä½“ID
            task_id: ä»»åŠ¡IDï¼ˆç”¨äºè¿›åº¦æ›´æ–°ï¼‰
            on_batch_complete: æ‰¹æ¬¡å®Œæˆå›è°ƒå‡½æ•°ï¼Œç­¾å: (test_cases: List[dict]) -> int
            progress_offset: è¿›åº¦åç§»é‡ï¼ˆç”¨äºå¤šé˜¶æ®µä»»åŠ¡ï¼‰
            progress_scale: è¿›åº¦ç¼©æ”¾æ¯”ä¾‹ï¼ˆç”¨äºå¤šé˜¶æ®µä»»åŠ¡ï¼‰
        """
        from app.services.async_task_manager import task_manager
        from app.models.requirement import RequirementFile
        
        if self.db:
            task_manager.load_config_from_db(self.db)
            self._load_config()  # åŒæ­¥åŠ è½½é…ç½®
        concurrency = task_manager.max_concurrent_tasks
        
        print(f"\nğŸš€ æ‰¹é‡æµ‹è¯•ç”¨ä¾‹è®¾è®¡: {len(test_points)} ä¸ªæµ‹è¯•ç‚¹ (æ‰¹æ¬¡ç”Ÿæˆ)")
        print(f"ğŸ”§ é…ç½®: å¹¶å‘={concurrency}, é‡è¯•={self._retry_count}æ¬¡, è¶…æ—¶={self._task_timeout}s")
        
        # æŸ¥è¯¢è¯¥æ¨¡å—çš„æ‰€æœ‰éœ€æ±‚æ–‡æ¡£
        requirement_content = ""
        if self.db:
            try:
                requirement_files = self.db.query(RequirementFile).filter(
                    RequirementFile.module_id == module_id,
                    RequirementFile.is_extracted == True
                ).all()
                
                if requirement_files:
                    content_parts = []
                    for file in requirement_files:
                        if file.extracted_content:
                            content_parts.append(f"ã€éœ€æ±‚æ–‡æ¡£ï¼š{file.filename}ã€‘\n{file.extracted_content}")
                    requirement_content = "\n\n---\n\n".join(content_parts)
                    print(f"ğŸ“„ å·²åŠ è½½ {len(requirement_files)} ä¸ªéœ€æ±‚æ–‡æ¡£ä½œä¸ºä¸Šä¸‹æ–‡")
                else:
                    print(f"âš ï¸ æ¨¡å— {module_id} æ²¡æœ‰æ‰¾åˆ°éœ€æ±‚æ–‡æ¡£")
            except Exception as e:
                print(f"âš ï¸ æŸ¥è¯¢éœ€æ±‚æ–‡æ¡£å¤±è´¥: {e}")
        
        try:
            all_cases = []
            total_saved = 0
            semaphore = asyncio.Semaphore(concurrency)
            completed = 0
            lock = asyncio.Lock()
            
            # æ™ºèƒ½åˆ†ç»„ï¼šå°†æµ‹è¯•ç‚¹åˆ†æˆæ‰¹æ¬¡ï¼ˆæ¯æ‰¹æœ€å¤š3ä¸ªï¼‰
            BATCH_SIZE = 3
            batches = [
                test_points[i:i+BATCH_SIZE] 
                for i in range(0, len(test_points), BATCH_SIZE)
            ]
            
            print(f"ğŸ“¦ æ™ºèƒ½åˆ†ç»„: {len(test_points)} ä¸ªæµ‹è¯•ç‚¹ â†’ {len(batches)} ä¸ªæ‰¹æ¬¡ï¼ˆæ¯æ‰¹æœ€å¤š{BATCH_SIZE}ä¸ªï¼‰")
            
            async def process_batch(batch, batch_idx):
                nonlocal completed, total_saved
                async with semaphore:
                    try:
                        batch_size = len(batch)
                        print(f"\nğŸ”„ æ‰¹æ¬¡ {batch_idx+1}/{len(batches)}: å¤„ç† {batch_size} ä¸ªæµ‹è¯•ç‚¹")
                        
                        # æ‰¹é‡è°ƒç”¨AIï¼ˆä¸€æ¬¡ç”Ÿæˆå¤šä¸ªï¼‰
                        cases = await self.design_test_cases_batch(
                            agent_id=agent_id,
                            test_points=batch,
                            requirement_content=requirement_content
                        )
                        
                        # ç»§æ‰¿æµ‹è¯•ç‚¹çš„å±æ€§
                        for i, case in enumerate(cases):
                            if i < len(batch):
                                tp = batch[i]
                                case["test_point_id"] = tp.get('id')
                                case["test_type"] = tp.get('test_type', 'functional')
                                case["design_method"] = tp.get('design_method')
                                case["priority"] = tp.get('priority', 'medium')
                                case["created_by_ai"] = True
                                
                                if batch_size <= 3:  # å°æ‰¹æ¬¡æ˜¾ç¤ºè¯¦ç»†ä¿¡æ¯
                                    print(f"   ğŸ“ ç”¨ä¾‹: {case.get('title', '')[:30]}... (ç»§æ‰¿: {case['test_type']}/{case['design_method']}/{case['priority']})")
                        
                        # ä¿å­˜åˆ°æ•°æ®åº“
                        saved_count = 0
                        if on_batch_complete and cases:
                            try:
                                saved_count = on_batch_complete(cases)
                                print(f"ğŸ’¾ æ‰¹æ¬¡ {batch_idx+1}: å·²ä¿å­˜ {saved_count} ä¸ªç”¨ä¾‹åˆ°æ•°æ®åº“")
                            except Exception as save_err:
                                print(f"âš ï¸ æ‰¹æ¬¡ {batch_idx+1}: ä¿å­˜å¤±è´¥ - {save_err}")
                        
                        async with lock:
                            completed += batch_size
                            total_saved += saved_count
                            all_cases.extend(cases)
                            if task_id:
                                # è®¡ç®—å¸¦åç§»çš„è¿›åº¦
                                raw_progress = (completed / len(test_points)) * 100
                                scaled_progress = progress_offset + raw_progress * progress_scale
                                task_manager.update_progress(task_id, int(scaled_progress))
                        
                        print(f"âœ… æ‰¹æ¬¡ {batch_idx+1}/{len(batches)}: å®Œæˆï¼Œç”Ÿæˆ {len(cases)} ä¸ªç”¨ä¾‹")
                        return cases
                        
                    except Exception as e:
                        import traceback
                        print(f"\n{'='*80}")
                        print(f"âŒ æ‰¹æ¬¡ {batch_idx+1}/{len(batches)}: å¤±è´¥")
                        print(f"{'='*80}")
                        print(f"é”™è¯¯ç±»å‹: {type(e).__name__}")
                        print(f"é”™è¯¯ä¿¡æ¯: {str(e)}")
                        print(f"æµ‹è¯•ç‚¹æ•°é‡: {len(batch)}")
                        print(f"æµ‹è¯•ç‚¹å†…å®¹:")
                        for i, tp in enumerate(batch):
                            print(f"  {i+1}. {tp.get('content', 'N/A')[:50]}... (æ–¹æ³•: {tp.get('design_method', 'N/A')})")
                        print(f"\nå®Œæ•´å †æ ˆ:")
                        traceback.print_exc()
                        print(f"{'='*80}\n")
                        # æ ‡è®°æ‰¹æ¬¡å¤±è´¥ï¼Œä½†ç»§ç»­å¤„ç†å…¶ä»–æ‰¹æ¬¡
                        async with lock:
                            completed += len(batch)
                            if task_id:
                                raw_progress = (completed / len(test_points)) * 100
                                scaled_progress = progress_offset + raw_progress * progress_scale
                                task_manager.update_progress(task_id, int(scaled_progress))
                        return []
            
            # å¹¶å‘å¤„ç†æ‰€æœ‰æ‰¹æ¬¡
            await asyncio.gather(*[process_batch(batch, i) for i, batch in enumerate(batches)])
            
            print(f"ğŸ‰ å®Œæˆ, å…± {len(all_cases)} ä¸ªç”¨ä¾‹, å·²ä¿å­˜ {total_saved} ä¸ª")
            return {
                "success": True, 
                "data": {
                    "test_cases": all_cases,
                    "saved_count": total_saved,
                    "total_generated": len(all_cases)
                }
            }
        except Exception as e:
            return {"success": False, "error": str(e)}
    
    def _normalize_test_case(self, data: Dict[str, Any]) -> Dict[str, Any]:
        """æ ‡å‡†åŒ–æµ‹è¯•ç”¨ä¾‹æ ¼å¼ï¼Œç¡®ä¿ä¸æ•°æ®åº“Schemaä¸€è‡´"""
        if not data:
            return data
        
        # æ•°ç»„è½¬å­—ç¬¦ä¸²
        def to_string(val):
            if isinstance(val, list):
                return '\n'.join(str(v) for v in val)
            return val
        
        # æ ‡å‡†åŒ–test_stepsæ ¼å¼
        def normalize_steps(steps):
            if not steps or not isinstance(steps, list):
                return steps
            result = []
            for i, s in enumerate(steps):
                if isinstance(s, dict):
                    result.append({
                        "step": s.get("step", i + 1),
                        "action": s.get("action") or s.get("æ“ä½œ", ""),
                        "expected": s.get("expected") or s.get("é¢„æœŸç»“æœ") or s.get("expected_result", "")
                    })
                elif isinstance(s, str):
                    result.append({"step": i + 1, "action": s, "expected": ""})
            return result
        
        return {
            "title": data.get("title"),
            "description": to_string(data.get("description")),
            "preconditions": to_string(data.get("preconditions")),
            "test_steps": normalize_steps(data.get("test_steps")),
            "expected_result": to_string(data.get("expected_result")),
            "design_method": data.get("design_method"),
            "test_type": data.get("test_type"),
            "priority": data.get("priority"),
        }
    
    def _simplify_test_case(self, tc: Dict[str, Any]) -> Dict[str, Any]:
        """ç®€åŒ–æµ‹è¯•ç”¨ä¾‹ï¼Œåªä¿ç•™æ ¸å¿ƒå­—æ®µä¼ ç»™AI"""
        return {
            "id": tc.get("id"),
            "test_point_id": tc.get("test_point_id"),
            "module_id": tc.get("module_id"),
            "title": tc.get("title"),
            "description": tc.get("description"),
            "preconditions": tc.get("preconditions"),
            "test_steps": tc.get("test_steps"),
        }
    
    async def execute_test_case_optimization(
        self, 
        original_test_cases: List[dict], 
        review_feedback: List[dict] = None, 
        optimization_requirements: str = "", 
        user_id: int = 1, 
        agent_id: Optional[int] = None, 
        batch_mode: bool = False, 
        task_id: Optional[str] = None,
        progress_offset: float = 0,  # è¿›åº¦åç§»ï¼ˆ0-100ï¼‰
        progress_scale: float = 1.0  # è¿›åº¦ç¼©æ”¾æ¯”ä¾‹ï¼ˆ0-1ï¼‰
    ) -> Dict[str, Any]:
        """æ‰¹é‡ä¼˜åŒ–æµ‹è¯•ç”¨ä¾‹ï¼ˆå¹¶å‘æ‰¹é‡å¤„ç†ï¼‰
        
        æ¯æ‰¹æ¬¡æœ€å¤š6ä¸ªç”¨ä¾‹ï¼Œä½¿ç”¨ç³»ç»Ÿè®¾ç½®çš„å¹¶å‘æ•°æ§åˆ¶åŒæ—¶æ‰§è¡Œçš„æ‰¹æ¬¡æ•°
        
        Args:
            progress_offset: è¿›åº¦åç§»é‡ï¼ˆç”¨äºå¤šé˜¶æ®µä»»åŠ¡ï¼‰
            progress_scale: è¿›åº¦ç¼©æ”¾æ¯”ä¾‹ï¼ˆç”¨äºå¤šé˜¶æ®µä»»åŠ¡ï¼‰
        """
        from app.services.async_task_manager import task_manager
        if self.db:
            task_manager.load_config_from_db(self.db)
            self._load_config()  # åŒæ­¥åŠ è½½é…ç½®
        
        BATCH_SIZE = 3  # æ¯æ‰¹æ¬¡æœ€å¤š3ä¸ªç”¨ä¾‹ï¼ˆå‡å°æ‰¹æ¬¡å¤§å°ï¼Œé¿å…è¶…æ—¶ï¼‰
        concurrency = task_manager.max_concurrent_tasks  # ä½¿ç”¨ç³»ç»Ÿè®¾ç½®çš„å¹¶å‘æ•°
        
        # åˆ†æ‰¹
        batches = [original_test_cases[i:i+BATCH_SIZE] for i in range(0, len(original_test_cases), BATCH_SIZE)]
        total_batches = len(batches)
        
        print(f"\nğŸš€ æ‰¹é‡æµ‹è¯•ç”¨ä¾‹ä¼˜åŒ–: {len(original_test_cases)} ä¸ªç”¨ä¾‹, åˆ† {total_batches} æ‰¹å¤„ç†")
        print(f"ğŸ”§ é…ç½®: å¹¶å‘={concurrency}, é‡è¯•={self._retry_count}æ¬¡, è¶…æ—¶={self._task_timeout}s")
        
        try:
            all_results = []
            completed = 0
            lock = asyncio.Lock()
            semaphore = asyncio.Semaphore(concurrency)  # æ§åˆ¶å¹¶å‘æ•°
            
            async def process_batch(batch_idx: int, batch: List[dict]):
                """å¤„ç†å•ä¸ªæ‰¹æ¬¡"""
                nonlocal completed
                
                async with semaphore:  # æ§åˆ¶å¹¶å‘
                    # ç®€åŒ–ä¼ ç»™AIçš„æ•°æ®
                    simplified_batch = [self._simplify_test_case(tc) for tc in batch]
                    
                    print(f"ğŸ“¦ å¤„ç†ç¬¬ {batch_idx+1}/{total_batches} æ‰¹ï¼Œå…± {len(batch)} ä¸ªç”¨ä¾‹")
                    
                    batch_results = []
                    
                    try:
                        # ä¸€æ¬¡AIè°ƒç”¨å¤„ç†æ•´æ‰¹
                        result = await self.optimize_test_cases(agent_id, simplified_batch)
                        optimized_cases = result.get("optimized_cases", [])
                        
                        # åˆ›å»ºidåˆ°åŸå§‹ç”¨ä¾‹çš„æ˜ å°„
                        original_map = {tc.get("id"): tc for tc in batch}
                        
                        # å¤„ç†è¿”å›çš„ä¼˜åŒ–ç»“æœ
                        for opt in optimized_cases:
                            tc_id = opt.get("id")
                            original = original_map.get(tc_id)
                            if original:
                                normalized = self._normalize_test_case(opt)
                                if normalized and normalized.get("title"):
                                    normalized["id"] = tc_id
                                    batch_results.append({
                                        "original": original,
                                        "optimized": normalized,
                                        "success": True,
                                        "improvements": []
                                    })
                                    print(f"   âœ… [{batch_idx+1}] ä¼˜åŒ–æˆåŠŸ: {normalized.get('title', '')[:30]}...")
                                else:
                                    batch_results.append({
                                        "original": original,
                                        "optimized": None,
                                        "success": False,
                                        "error": "ä¼˜åŒ–ç»“æœæ— æ•ˆ"
                                    })
                        
                        # æ£€æŸ¥æ˜¯å¦æœ‰é—æ¼çš„ç”¨ä¾‹
                        returned_ids = {opt.get("id") for opt in optimized_cases}
                        for tc in batch:
                            if tc.get("id") not in returned_ids:
                                batch_results.append({
                                    "original": tc,
                                    "optimized": None,
                                    "success": False,
                                    "error": "AIæœªè¿”å›è¯¥ç”¨ä¾‹çš„ä¼˜åŒ–ç»“æœ"
                                })
                                print(f"   âš ï¸ [{batch_idx+1}] ç”¨ä¾‹ {tc.get('id')} æœªè¢«ä¼˜åŒ–")
                        
                    except Exception as e:
                        print(f"âŒ ç¬¬ {batch_idx+1} æ‰¹å¤„ç†å¤±è´¥: {e}")
                        for tc in batch:
                            batch_results.append({
                                "original": tc,
                                "optimized": None,
                                "success": False,
                                "error": str(e)
                            })
                    
                    # æ›´æ–°è¿›åº¦ï¼ˆçº¿ç¨‹å®‰å…¨ï¼‰
                    async with lock:
                        completed += 1
                        all_results.extend(batch_results)
                        if task_id:
                            raw_progress = (completed / total_batches) * 100
                            scaled_progress = progress_offset + raw_progress * progress_scale
                            # æ›´æ–°è¿›åº¦å’Œæ¶ˆæ¯
                            success_in_batch = sum(1 for r in batch_results if r.get("success"))
                            total_success = sum(1 for r in all_results if r.get("success"))
                            task_manager.update_progress(
                                task_id, 
                                int(scaled_progress), 
                                f"æ­£åœ¨ä¼˜åŒ–æµ‹è¯•ç”¨ä¾‹... ({total_success}/{len(original_test_cases)})"
                            )
                    
                    return batch_results
            
            # å¹¶å‘å¤„ç†æ‰€æœ‰æ‰¹æ¬¡
            await asyncio.gather(*[process_batch(i, batch) for i, batch in enumerate(batches)])
            
            success_count = sum(1 for r in all_results if r.get("success"))
            print(f"ğŸ‰ ä¼˜åŒ–å®Œæˆ, æˆåŠŸ {success_count}/{len(original_test_cases)} ä¸ª")
            
            return {"success": True, "data": {
                "optimized_results": all_results,
                "optimized_cases": [r["optimized"] for r in all_results if r.get("optimized")],
                "statistics": {"total": len(original_test_cases), "success_count": success_count}
            }}
        except Exception as e:
            return {"success": False, "error": str(e)}

    async def execute_full_generation_pipeline(
        self,
        requirement_content: str,
        file_id: int,
        module_id: int,
        user_id: int,
        agent_ids: Dict[str, int],
        image_paths: Optional[List[str]] = None,
        task_id: Optional[str] = None
    ) -> Dict[str, Any]:
        """æ‰§è¡Œå®Œæ•´çš„ç”Ÿæˆæµç¨‹ï¼šéœ€æ±‚ç‚¹ â†’ æµ‹è¯•ç‚¹ â†’ æµ‹è¯•ç”¨ä¾‹ â†’ ä¼˜åŒ–
        
        Args:
            requirement_content: éœ€æ±‚æ–‡æ¡£å†…å®¹
            file_id: éœ€æ±‚æ–‡ä»¶ID
            module_id: æ¨¡å—ID
            user_id: ç”¨æˆ·ID
            agent_ids: æ™ºèƒ½ä½“IDå­—å…¸ {"requirement": id, "test_point": id, "test_case": id, "optimizer": id}
            image_paths: å›¾ç‰‡è·¯å¾„åˆ—è¡¨
            task_id: ä»»åŠ¡ID
            
        Returns:
            åŒ…å«æ‰€æœ‰ç”Ÿæˆç»“æœçš„å­—å…¸
        """
        from app.services.async_task_manager import task_manager
        from app.models.requirement import RequirementPoint
        from app.models.testcase import TestPoint, TestCase
        
        if self.db:
            task_manager.load_config_from_db(self.db)
            self._load_config()
        
        try:
            # ========== é˜¶æ®µ1ï¼šç”Ÿæˆéœ€æ±‚ç‚¹ (0-25%) ==========
            if task_id:
                task_manager.update_progress(task_id, 0, "æ­£åœ¨åˆ†æéœ€æ±‚æ–‡æ¡£...")
            
            print("\n" + "="*60)
            print("ğŸš€ å¼€å§‹å®Œæ•´ç”Ÿæˆæµç¨‹")
            print("="*60)
            print(f"ğŸ“„ éœ€æ±‚æ–‡ä»¶ID: {file_id}")
            print(f"ğŸ“¦ æ¨¡å—ID: {module_id}")
            print(f"ğŸ‘¤ ç”¨æˆ·ID: {user_id}")
            
            # ========== æ¸…ç©ºç°æœ‰æ•°æ® ==========
            # æ¸…ç©ºè¯¥éœ€æ±‚æ–‡ä»¶ç›¸å…³çš„æ‰€æœ‰éœ€æ±‚ç‚¹ï¼ˆçº§è”åˆ é™¤ä¼šè‡ªåŠ¨åˆ é™¤å…³è”çš„æµ‹è¯•ç‚¹å’Œæµ‹è¯•ç”¨ä¾‹ï¼‰
            existing_points = self.db.query(RequirementPoint).filter(
                RequirementPoint.requirement_file_id == file_id
            ).all()
            
            if existing_points:
                print(f"\nğŸ—‘ï¸  æ¸…ç©ºç°æœ‰æ•°æ®: {len(existing_points)} ä¸ªéœ€æ±‚ç‚¹ï¼ˆåŠå…¶å…³è”çš„æµ‹è¯•ç‚¹å’Œæµ‹è¯•ç”¨ä¾‹ï¼‰")
                for point in existing_points:
                    self.db.delete(point)
                self.db.flush()
            
            # ç”Ÿæˆéœ€æ±‚ç‚¹
            req_result = await self.analyze_requirements(
                agent_id=agent_ids.get("requirement"),
                content=requirement_content,
                image_paths=image_paths
            )
            
            requirement_points_data = req_result.get("requirement_points", [])
            print(f"\nâœ… [1/4] éœ€æ±‚ç‚¹ç”Ÿæˆå®Œæˆ: {len(requirement_points_data)} ä¸ª")
            
            # è°ƒè¯•ï¼šè¾“å‡ºå‰3ä¸ªéœ€æ±‚ç‚¹çš„åŸå§‹æ•°æ®
            if requirement_points_data:
                print(f"\nğŸ“Š [è°ƒè¯•] å‰3ä¸ªéœ€æ±‚ç‚¹çš„åŸå§‹æ•°æ®:")
                for i, rp in enumerate(requirement_points_data[:3]):
                    print(f"  éœ€æ±‚ç‚¹ {i+1}: priority={rp.get('priority')}, content={rp.get('content', '')[:50]}...")
            
            if not requirement_points_data:
                raise Exception("æœªç”Ÿæˆä»»ä½•éœ€æ±‚ç‚¹")
            
            # ä¿å­˜éœ€æ±‚ç‚¹åˆ°æ•°æ®åº“
            requirement_points = []
            for idx, rp_data in enumerate(requirement_points_data):
                # æ ‡å‡†åŒ–ä¼˜å…ˆçº§
                raw_priority = rp_data.get("priority", "medium")
                normalized_priority = self._normalize_priority(raw_priority)
                
                rp = RequirementPoint(
                    requirement_file_id=file_id,
                    module_id=module_id,
                    content=rp_data.get("content", ""),
                    order_num=rp_data.get("order_index", idx),
                    priority=normalized_priority,
                    source="ai_generated",
                    created_by_ai=True,
                    created_by=user_id
                )
                self.db.add(rp)
                requirement_points.append(rp)
            
            self.db.flush()
            for rp in requirement_points:
                self.db.refresh(rp)
            
            if task_id:
                task_manager.update_progress(task_id, 25, f"éœ€æ±‚ç‚¹ç”Ÿæˆå®Œæˆï¼Œå…± {len(requirement_points)} ä¸ª")
            
            # ========== é˜¶æ®µ2ï¼šç”Ÿæˆæµ‹è¯•ç‚¹ (25-50%) ==========
            print(f"\nğŸ”„ [2/4] å¼€å§‹ç”Ÿæˆæµ‹è¯•ç‚¹...")
            
            req_points_for_generation = [{"id": rp.id, "content": rp.content} for rp in requirement_points]
            
            tp_result = await self.execute_test_point_generation(
                requirement_points=req_points_for_generation,
                user_id=user_id,
                agent_id=agent_ids.get("test_point"),
                task_id=task_id,  # ä¼ å…¥task_idä»¥æ”¯æŒæ‰¹æ¬¡çº§è¿›åº¦æ›´æ–°
                progress_offset=25,  # ä»25%å¼€å§‹
                progress_scale=0.25  # å 25%è¿›åº¦
            )
            
            if not tp_result.get("success"):
                raise Exception(f"æµ‹è¯•ç‚¹ç”Ÿæˆå¤±è´¥: {tp_result.get('error')}")
            
            test_points_data = tp_result.get("data", {}).get("test_points", [])
            print(f"âœ… [2/4] æµ‹è¯•ç‚¹ç”Ÿæˆå®Œæˆ: {len(test_points_data)} ä¸ª")
            
            # ä¿å­˜æµ‹è¯•ç‚¹åˆ°æ•°æ®åº“
            test_points = []
            for tp_data in test_points_data:
                # æ ‡å‡†åŒ–ä¼˜å…ˆçº§
                raw_priority = tp_data.get("priority", "medium")
                normalized_priority = self._normalize_priority(raw_priority)
                
                tp = TestPoint(
                    requirement_point_id=tp_data.get("requirement_point_id"),
                    module_id=module_id,
                    content=tp_data.get("content", ""),
                    test_type=tp_data.get("test_type", "functional"),
                    design_method=tp_data.get("design_method"),  # æµ‹è¯•è®¾è®¡æ–¹æ³•
                    priority=normalized_priority,
                    created_by_ai=True,
                    created_by=user_id
                )
                self.db.add(tp)
                test_points.append(tp)
            
            self.db.flush()
            for tp in test_points:
                self.db.refresh(tp)
            
            if task_id:
                task_manager.update_progress(task_id, 50, f"æµ‹è¯•ç‚¹ç”Ÿæˆå®Œæˆï¼Œå…± {len(test_points)} ä¸ª")
            
            # ========== é˜¶æ®µ3ï¼šç”Ÿæˆæµ‹è¯•ç”¨ä¾‹ (50-85%) ==========
            print(f"\nğŸ”„ [3/4] å¼€å§‹ç”Ÿæˆæµ‹è¯•ç”¨ä¾‹...")
            
            # ä¼ é€’å®Œæ•´çš„æµ‹è¯•ç‚¹æ•°æ®ï¼ˆåŒ…å«æ‰€æœ‰å¿…è¦å­—æ®µï¼‰
            test_points_for_generation = [{
                "id": tp.id, 
                "content": tp.content,
                "test_type": tp.test_type,
                "design_method": tp.design_method,
                "priority": tp.priority,
                "requirement_point_id": tp.requirement_point_id
            } for tp in test_points]
            
            # ç”¨äºæ”¶é›†æ‰€æœ‰ä¿å­˜çš„æµ‹è¯•ç”¨ä¾‹ï¼ˆå­—å…¸æ ¼å¼ï¼Œç”¨äºä¼˜åŒ–ï¼‰
            saved_test_cases_for_optimization = []
            
            # å®šä¹‰ä¿å­˜å›è°ƒ
            def save_test_cases(cases: List[dict]) -> int:
                """ä¿å­˜æµ‹è¯•ç”¨ä¾‹åˆ°æ•°æ®åº“ï¼Œå¹¶æ”¶é›†æ•°æ®ç”¨äºä¼˜åŒ–"""
                nonlocal saved_test_cases_for_optimization
                saved_count = 0
                batch_objects = []  # å½“å‰æ‰¹æ¬¡çš„å¯¹è±¡
                
                print(f"   ğŸ“¥ æ”¶åˆ° {len(cases)} ä¸ªç”¨ä¾‹å¾…ä¿å­˜")
                
                for case_data in cases:
                    try:
                        tc = TestCase(
                            test_point_id=case_data.get("test_point_id"),
                            module_id=module_id,
                            title=case_data.get("title", ""),
                            description=case_data.get("description", ""),
                            preconditions=case_data.get("preconditions", ""),
                            test_steps=case_data.get("test_steps", ""),
                            expected_result=case_data.get("expected_result", ""),
                            design_method=case_data.get("design_method", ""),
                            test_category=case_data.get("test_type", "functional"),  # æµ‹è¯•ç±»åˆ«
                            priority=case_data.get("priority", "medium"),
                            created_by_ai=True,
                            created_by=user_id
                        )
                        self.db.add(tc)
                        batch_objects.append(tc)
                        saved_count += 1
                    except Exception as e:
                        print(f"   âš ï¸ åˆ›å»ºæµ‹è¯•ç”¨ä¾‹å¯¹è±¡å¤±è´¥: {e}")
                        continue
                
                # ç«‹å³flushå¹¶commitå½“å‰æ‰¹æ¬¡
                try:
                    self.db.flush()
                    for tc in batch_objects:
                        self.db.refresh(tc)
                        # ä¿å­˜ä¸ºå­—å…¸æ ¼å¼ï¼ˆä¸ç›´æ¥ç”Ÿæˆæµ‹è¯•ç”¨ä¾‹çš„æ–¹å¼ä¸€è‡´ï¼‰
                        saved_test_cases_for_optimization.append({
                            "id": tc.id,
                            "title": tc.title,
                            "description": tc.description,
                            "preconditions": tc.preconditions,
                            "test_steps": tc.test_steps,
                            "expected_result": tc.expected_result
                        })
                    # æ¯æ‰¹æ¬¡æäº¤ï¼Œç¡®ä¿æ•°æ®æŒä¹…åŒ–
                    self.db.commit()
                    print(f"   ğŸ’¾ æ‰¹æ¬¡ä¿å­˜æˆåŠŸ: {saved_count} ä¸ªç”¨ä¾‹ï¼Œæ€»è®¡: {len(saved_test_cases_for_optimization)} ä¸ª")
                except Exception as e:
                    print(f"   âŒ æ‰¹æ¬¡æäº¤å¤±è´¥: {e}")
                    self.db.rollback()
                    return 0
                
                return saved_count
            
            tc_result = await self.execute_test_case_design_batch(
                test_points=test_points_for_generation,
                module_id=module_id,
                user_id=user_id,
                agent_id=agent_ids.get("test_case"),
                task_id=task_id,
                on_batch_complete=save_test_cases,
                progress_offset=50,
                progress_scale=0.25  # æ”¹ä¸ºå 25%è¿›åº¦ï¼ˆåŸæ¥æ˜¯0.35ï¼‰
            )
            
            if not tc_result.get("success"):
                raise Exception(f"æµ‹è¯•ç”¨ä¾‹ç”Ÿæˆå¤±è´¥: {tc_result.get('error')}")
            
            generated_cases = tc_result.get("data", {}).get("test_cases", [])
            print(f"âœ… [3/4] æµ‹è¯•ç”¨ä¾‹ç”Ÿæˆå®Œæˆ: {len(generated_cases)} ä¸ª")
            print(f"ğŸ’¾ å·²ä¿å­˜åˆ°æ•°æ®åº“: {len(saved_test_cases_for_optimization)} ä¸ªæµ‹è¯•ç”¨ä¾‹")
            
            if task_id:
                task_manager.update_progress(task_id, 75, f"æµ‹è¯•ç”¨ä¾‹ç”Ÿæˆå®Œæˆï¼Œå…± {len(generated_cases)} ä¸ª")
            
            # ========== é˜¶æ®µ4ï¼šä¼˜åŒ–æµ‹è¯•ç”¨ä¾‹ (75-100%) ==========
            print(f"\nğŸ”„ [4/4] å¼€å§‹ä¼˜åŒ–æµ‹è¯•ç”¨ä¾‹...")
            
            # æ£€æŸ¥æ˜¯å¦æœ‰æµ‹è¯•ç”¨ä¾‹éœ€è¦ä¼˜åŒ–
            if not saved_test_cases_for_optimization:
                print(f"âš ï¸ æ²¡æœ‰æ‰¾åˆ°å·²ä¿å­˜çš„æµ‹è¯•ç”¨ä¾‹ï¼Œè·³è¿‡ä¼˜åŒ–é˜¶æ®µ")
                # ç›´æ¥æäº¤å¹¶å®Œæˆ
                self.db.commit()
                if task_id:
                    task_manager.update_progress(task_id, 100, "ç”Ÿæˆå®Œæˆï¼")
                    task_manager.complete_task(task_id, {
                        "requirement_points_count": len(requirement_points),
                        "test_points_count": len(test_points),
                        "test_cases_count": len(generated_cases)
                    })
                return {
                    "success": True,
                    "data": {
                        "requirement_points_count": len(requirement_points),
                        "test_points_count": len(test_points),
                        "test_cases_count": len(generated_cases)
                    }
                }
            
            print(f"ğŸ“‹ å‡†å¤‡ä¼˜åŒ– {len(saved_test_cases_for_optimization)} ä¸ªæµ‹è¯•ç”¨ä¾‹")
            
            # æ›´æ–°è¿›åº¦æ¶ˆæ¯ï¼Œè¿›å…¥ä¼˜åŒ–é˜¶æ®µ
            if task_id:
                task_manager.update_progress(task_id, 75, f"æ­£åœ¨ä¼˜åŒ–æµ‹è¯•ç”¨ä¾‹...")
            
            opt_result = await self.execute_test_case_optimization(
                original_test_cases=saved_test_cases_for_optimization,
                user_id=user_id,
                agent_id=agent_ids.get("optimizer"),
                batch_mode=True,
                task_id=task_id,
                progress_offset=75,
                progress_scale=0.25
            )
            
            # åº”ç”¨ä¼˜åŒ–ç»“æœåˆ°æ•°æ®åº“
            optimized_count = 0
            if opt_result.get("success"):
                optimized_results = opt_result.get("data", {}).get("optimized_results", [])
                print(f"ğŸ“ æ”¶åˆ° {len(optimized_results)} ä¸ªä¼˜åŒ–ç»“æœ")
                
                for opt_result_item in optimized_results:
                    if opt_result_item.get("success") and opt_result_item.get("optimized"):
                        original_id = opt_result_item.get("original", {}).get("id")
                        if original_id:
                            try:
                                optimized = opt_result_item["optimized"]
                                tc = self.db.query(TestCase).filter(TestCase.id == original_id).first()
                                if tc:
                                    tc.title = optimized.get("title", tc.title)
                                    tc.description = optimized.get("description", tc.description)
                                    tc.preconditions = optimized.get("preconditions", tc.preconditions)
                                    tc.test_steps = optimized.get("test_steps", tc.test_steps)
                                    tc.expected_result = optimized.get("expected_result", tc.expected_result)
                                    optimized_count += 1
                            except Exception as e:
                                print(f"âš ï¸ æ›´æ–°ä¼˜åŒ–ç»“æœå¤±è´¥ (ID={original_id}): {e}")
                
                print(f"âœ… [4/4] æµ‹è¯•ç”¨ä¾‹ä¼˜åŒ–å®Œæˆ: æˆåŠŸä¼˜åŒ– {optimized_count} ä¸ªç”¨ä¾‹")
            else:
                print(f"âš ï¸ [4/4] æµ‹è¯•ç”¨ä¾‹ä¼˜åŒ–å¤±è´¥ï¼Œè·³è¿‡æ­¤æ­¥éª¤")
            
            # å…ˆæäº¤æ‰€æœ‰æ•°æ®åº“æ›´æ”¹
            print(f"\nğŸ’¾ æ­£åœ¨æäº¤æ‰€æœ‰æ•°æ®åˆ°æ•°æ®åº“...")
            self.db.commit()
            print(f"âœ… æ•°æ®åº“æäº¤æˆåŠŸ")
            
            # éªŒè¯æ•°æ®æ˜¯å¦çœŸçš„ä¿å­˜äº†
            saved_count = self.db.query(TestCase).filter(TestCase.module_id == module_id).count()
            print(f"ğŸ“Š æ•°æ®åº“éªŒè¯: æ¨¡å— {module_id} å…±æœ‰ {saved_count} ä¸ªæµ‹è¯•ç”¨ä¾‹")
            
            # ç„¶åæ ‡è®°ä»»åŠ¡å®Œæˆ
            if task_id:
                task_manager.update_progress(task_id, 100, "ç”Ÿæˆå®Œæˆï¼")
                result_data = {
                    "requirement_points_count": len(requirement_points),
                    "test_points_count": len(test_points),
                    "test_cases_count": len(saved_test_cases_for_optimization),
                    "optimized_count": optimized_count
                }
                task_manager.complete_task(task_id, result_data)
                print(f"âœ… ä»»åŠ¡çŠ¶æ€å·²æ›´æ–°ä¸ºå®Œæˆ")
                print(f"ğŸ“‹ ä»»åŠ¡ç»“æœ: {result_data}")
                
                # éªŒè¯ä»»åŠ¡çŠ¶æ€
                task_status = task_manager.get_task_status(task_id)
                print(f"ğŸ” ä»»åŠ¡çŠ¶æ€éªŒè¯: {task_status}")
            
            print("\n" + "="*60)
            print("ğŸ‰ å®Œæ•´ç”Ÿæˆæµç¨‹æ‰§è¡ŒæˆåŠŸï¼")
            print(f"   éœ€æ±‚ç‚¹: {len(requirement_points)} ä¸ª")
            print(f"   æµ‹è¯•ç‚¹: {len(test_points)} ä¸ª")
            print(f"   æµ‹è¯•ç”¨ä¾‹: {len(saved_test_cases_for_optimization)} ä¸ªï¼ˆå·²ä¿å­˜åˆ°æ•°æ®åº“ï¼‰")
            if optimized_count > 0:
                print(f"   ä¼˜åŒ–ç”¨ä¾‹: {optimized_count} ä¸ª")
            print("="*60)
            
            return {
                "success": True,
                "data": {
                    "requirement_points_count": len(requirement_points),
                    "test_points_count": len(test_points),
                    "test_cases_count": len(saved_test_cases_for_optimization),
                    "optimized_count": optimized_count
                }
            }
            
        except Exception as e:
            print(f"\nâŒ å®Œæ•´ç”Ÿæˆæµç¨‹å¤±è´¥: {e}")
            if task_id:
                task_manager.fail_task(task_id, str(e))
            # å³ä½¿å¤±è´¥ä¹Ÿæäº¤å·²ä¿å­˜çš„æ•°æ®
            try:
                self.db.commit()
            except:
                self.db.rollback()
            return {
                "success": False,
                "error": str(e)
            }


# å…¨å±€å®ä¾‹
agent_service_real = AgentServiceReal()
