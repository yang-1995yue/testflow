"""
AIæœåŠ¡ - è°ƒç”¨å¤§è¯­è¨€æ¨¡å‹
åªæ”¯æŒ OpenAI å…¼å®¹æ ¼å¼çš„ API è°ƒç”¨
æ”¯æŒæµå¼ç”Ÿæˆï¼Œé¿å…é•¿æ—¶é—´è¿æ¥è¶…æ—¶
"""
import json
import os
import base64
from typing import Dict, Any, List, Optional
import httpx


class AIService:
    """AIæœåŠ¡ç±» - ä½¿ç”¨ OpenAI å…¼å®¹æ ¼å¼è°ƒç”¨å¤§è¯­è¨€æ¨¡å‹"""
    
    def __init__(self):
        pass
    
    def encode_image_to_base64(self, image_path: str) -> str:
        """å°†å›¾ç‰‡æ–‡ä»¶ç¼–ç ä¸ºbase64å­—ç¬¦ä¸²"""
        with open(image_path, "rb") as f:
            return base64.b64encode(f.read()).decode("utf-8")
    
    def get_image_mime_type(self, image_path: str) -> str:
        """æ ¹æ®å›¾ç‰‡è·¯å¾„è·å–MIMEç±»å‹"""
        ext = image_path.lower().split(".")[-1]
        mime_types = {
            "png": "image/png",
            "jpg": "image/jpeg",
            "jpeg": "image/jpeg",
            "gif": "image/gif",
            "webp": "image/webp",
        }
        return mime_types.get(ext, "image/png")
    
    async def call_ai_stream(
        self,
        model: str,
        messages: List[Dict[str, Any]],
        api_key: str,
        base_url: str,
        temperature: float = 0.7,
        max_tokens: int = 2000
    ) -> str:
        """
        æµå¼è°ƒç”¨ OpenAI å…¼å®¹æ ¼å¼çš„ APIï¼Œæ”¶é›†æ‰€æœ‰è¾“å‡ºåè¿”å›
        
        Args:
            model: æ¨¡å‹ID
            messages: æ¶ˆæ¯åˆ—è¡¨
            api_key: APIå¯†é’¥
            base_url: APIåŸºç¡€URL
            temperature: æ¸©åº¦å‚æ•°
            max_tokens: æœ€å¤§ä»¤ç‰Œæ•°
            
        Returns:
            AIå“åº”å†…å®¹ï¼ˆå®Œæ•´æ”¶é›†åè¿”å›ï¼‰
        """
        # ç¡®ä¿ base_url æ ¼å¼æ­£ç¡®
        base_url = base_url.rstrip('/')
        if not base_url.endswith('/v1'):
            base_url = f"{base_url}/v1"
        
        url = f"{base_url}/chat/completions"
        
        headers = {
            "Authorization": f"Bearer {api_key}",
            "Content-Type": "application/json"
        }
        
        data = {
            "model": model,
            "messages": messages,
            "temperature": temperature,
            "max_tokens": max_tokens,
            "stream": True  # å¯ç”¨æµå¼è¾“å‡º
        }
        
        print(f"ğŸ¤– AIæµå¼è°ƒç”¨: model={model}, url={url}")
        
        collected_content = []
        
        try:
            async with httpx.AsyncClient(timeout=300.0) as client:  # å¢åŠ è¶…æ—¶æ—¶é—´
                async with client.stream("POST", url, headers=headers, json=data) as response:
                    print(f"ğŸ“¡ APIè¯·æ±‚: {response.status_code} {response.url}")
                    print(f"ğŸ“ è¯·æ±‚æ•°æ®: {json.dumps(data, ensure_ascii=False, indent=2)[:500]}...")
                    if response.status_code != 200:
                        error_text = await response.aread()
                        error_str = error_text.decode()
                        print(f"âŒ APIè°ƒç”¨å¤±è´¥: {response.status_code} - {error_str}")
                        raise Exception(f"APIè¿”å›é”™è¯¯: {response.status_code}ï¼Œè¯¦æƒ…: {error_str[:200]}...")
                    
                    async for line in response.aiter_lines():
                        if not line:
                            continue
                        
                        # å¤„ç† SSE æ ¼å¼
                        if line.startswith("data: "):
                            data_str = line[6:]  # å»æ‰ "data: " å‰ç¼€
                            
                            if data_str.strip() == "[DONE]":
                                break
                            
                            try:
                                chunk = json.loads(data_str)
                                if "choices" in chunk and chunk["choices"]:
                                    delta = chunk["choices"][0].get("delta", {})
                                    content = delta.get("content", "")
                                    if content:
                                        collected_content.append(content)
                            except json.JSONDecodeError:
                                continue
            
            full_content = "".join(collected_content)
            print(f"âœ… AIæµå¼å“åº”å®Œæˆï¼Œå†…å®¹é•¿åº¦: {len(full_content)}")
            print(f"ğŸ“ å®Œæ•´å“åº”å†…å®¹: {full_content}")
            
            # æ£€æŸ¥å“åº”å†…å®¹æ˜¯å¦æœ‰æ•ˆ
            if not full_content or len(full_content) < 10:  # å†…å®¹å¤ªçŸ­ï¼Œå¯èƒ½æ— æ•ˆ
                print(f"âŒ AIè¿”å›å†…å®¹è¿‡çŸ­: {len(full_content)} å­—ç¬¦")
                raise Exception(f"AIè¿”å›å†…å®¹æ— æ•ˆ: å†…å®¹è¿‡çŸ­ ({len(full_content)} å­—ç¬¦)")
            
            return full_content
                    
        except httpx.TimeoutException:
            print("âŒ APIè°ƒç”¨è¶…æ—¶")
            raise Exception("APIè°ƒç”¨è¶…æ—¶ï¼Œè¯·ç¨åé‡è¯•")
        except Exception as e:
            print(f"âŒ AIæµå¼è°ƒç”¨å¼‚å¸¸: {e}")
            raise
    
    async def call_ai(
        self,
        model: str,
        messages: List[Dict[str, Any]],
        api_key: str,
        base_url: str,
        temperature: float = 0.7,
        max_tokens: int = 2000
    ) -> str:
        """
        è°ƒç”¨ OpenAI å…¼å®¹æ ¼å¼çš„ APIï¼ˆä½¿ç”¨æµå¼æ¨¡å¼é¿å…è¶…æ—¶ï¼‰
        
        Args:
            model: æ¨¡å‹ID
            messages: æ¶ˆæ¯åˆ—è¡¨
            api_key: APIå¯†é’¥
            base_url: APIåŸºç¡€URL
            temperature: æ¸©åº¦å‚æ•°
            max_tokens: æœ€å¤§ä»¤ç‰Œæ•°
            
        Returns:
            AIå“åº”å†…å®¹
        """
        # é»˜è®¤ä½¿ç”¨æµå¼è°ƒç”¨
        return await self.call_ai_stream(
            model=model,
            messages=messages,
            api_key=api_key,
            base_url=base_url,
            temperature=temperature,
            max_tokens=max_tokens
        )
    
    async def call_ai_multimodal(
        self,
        model: str,
        text_content: str,
        image_paths: List[str],
        api_key: str,
        base_url: str,
        system_prompt: Optional[str] = None,
        temperature: float = 0.7,
        max_tokens: int = 4000
    ) -> str:
        """
        å¤šæ¨¡æ€AIè°ƒç”¨æ¥å£ - æ”¯æŒæ–‡æœ¬å’Œå›¾ç‰‡è¾“å…¥ï¼ˆOpenAIå…¼å®¹æ ¼å¼ï¼Œæµå¼æ¨¡å¼ï¼‰
        
        Args:
            model: æ¨¡å‹ID
            text_content: æ–‡æœ¬å†…å®¹
            image_paths: å›¾ç‰‡æ–‡ä»¶è·¯å¾„åˆ—è¡¨
            api_key: APIå¯†é’¥
            base_url: APIåŸºç¡€URL
            system_prompt: ç³»ç»Ÿæç¤ºè¯
            temperature: æ¸©åº¦å‚æ•°
            max_tokens: æœ€å¤§ä»¤ç‰Œæ•°
            
        Returns:
            AIå“åº”å†…å®¹
        """
        # æ„å»ºå¤šæ¨¡æ€æ¶ˆæ¯å†…å®¹
        content = [{"type": "text", "text": text_content}]
        
        # æ·»åŠ å›¾ç‰‡
        for image_path in image_paths:
            try:
                image_data = self.encode_image_to_base64(image_path)
                mime_type = self.get_image_mime_type(image_path)
                
                content.append({
                    "type": "image_url",
                    "image_url": {
                        "url": f"data:{mime_type};base64,{image_data}",
                        "detail": "high"
                    }
                })
            except Exception as e:
                print(f"âš ï¸ æ— æ³•åŠ è½½å›¾ç‰‡ {image_path}: {e}")
                continue
        
        # æ„å»ºæ¶ˆæ¯
        messages = []
        if system_prompt:
            messages.append({"role": "system", "content": system_prompt})
        messages.append({"role": "user", "content": content})
        
        try:
            # å°è¯•ä½¿ç”¨å¤šæ¨¡æ€è°ƒç”¨
            return await self.call_ai_stream(
                model=model,
                messages=messages,
                api_key=api_key,
                base_url=base_url,
                temperature=temperature,
                max_tokens=max_tokens
            )
        except Exception as e:
            # æ£€æŸ¥æ˜¯å¦æ˜¯"not a VLM"é”™è¯¯
            error_str = str(e)
            if "not a VLM" in error_str.lower() or "vision language model" in error_str.lower():
                print(f"âš ï¸ å¤šæ¨¡æ€è°ƒç”¨å¤±è´¥: {error_str}")
                print(f"ğŸ”„ è‡ªåŠ¨é™çº§ä¸ºçº¯æ–‡æœ¬è°ƒç”¨")
                
                # æ„å»ºçº¯æ–‡æœ¬æ¶ˆæ¯
                plain_messages = []
                if system_prompt:
                    plain_messages.append({"role": "system", "content": system_prompt})
                plain_messages.append({"role": "user", "content": text_content})
                
                # é™çº§ä¸ºçº¯æ–‡æœ¬è°ƒç”¨
                return await self.call_ai_stream(
                    model=model,
                    messages=plain_messages,
                    api_key=api_key,
                    base_url=base_url,
                    temperature=temperature,
                    max_tokens=max_tokens
                )
            else:
                # å…¶ä»–é”™è¯¯ï¼Œé‡æ–°æŠ›å‡º
                raise


# å…¨å±€AIæœåŠ¡å®ä¾‹
ai_service = AIService()
